{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e747279-b8af-459a-8357-0be3ecdac38a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0722f-c47a-4953-929d-e5e57dba912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import torch\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "os.chdir(\"..\")  # we are supposed to be in 'TIMEVIEW/experiments/analysis', so moving up to 'experiments'\n",
    "from datasets import load_dataset\n",
    "from baselines import YNormalizer\n",
    "from timeview.model import TTS\n",
    "\n",
    "\n",
    "SAVE_DIR = \".\"  # change if you want different location\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91f5012f-9571-4819-b3f9-bddedb43e4cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "from datasets import BetaDataset, SineTransDataset\n",
    "\n",
    "toplottt = []\n",
    "for name, random, n, builder in (\n",
    "    (\"Beta\", False, 900, BetaDataset),\n",
    "    (\"Beta\", True, 900, BetaDataset),\n",
    "    (\"Sine\", False, 200, SineTransDataset),\n",
    "    (\"Sine\", True, 200, SineTransDataset),\n",
    "):\n",
    "    dataset = builder(n, 20, random)\n",
    "    df = pd.merge(\n",
    "        pd.melt(pd.DataFrame(dataset.ts).reset_index(names=\"id\"), \"id\", value_name=\"t\"),\n",
    "        pd.melt(pd.DataFrame(dataset.ys).reset_index(names=\"id\"), \"id\", value_name=\"y\"),\n",
    "    ).assign(\n",
    "        name=name,\n",
    "        random=\"With Random\" if random else \"W/O Random\"\n",
    "    )\n",
    "    toplottt.append(df)\n",
    "toplottt = pd.concat(toplottt, ignore_index=True)\n",
    "toplottt[\"id\"] /= toplottt.groupby([\"name\", \"random\"])[\"id\"].transform(max)\n",
    "\n",
    "so.Plot(\n",
    "    toplottt,\n",
    "    x=\"t\",\n",
    "    y=\"y\",\n",
    "    color=\"id\",\n",
    ").add(\n",
    "    so.Lines(),\n",
    "    legend=False,\n",
    ").facet(\n",
    "    row=\"name\",\n",
    "    col=\"random\",\n",
    ").share(\n",
    "    x=False, y=False,\n",
    ").layout(\n",
    "    size=(8, 6),\n",
    ").label(x=\"\", y=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b3f65-aa5a-4f2b-9cfe-2bf17da07279",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"benchmarks/summary_expanded.csv\")\n",
    "results[[\"method\", \"ord_method\"]] = \"Original\", 0\n",
    "results.loc[results[\"p\"].notna(), [\"method\", \"ord_method\"]] = \"AR(1)\", 1\n",
    "results.loc[results[\"ar_num_hidden\"].notna(), [\"method\", \"ord_method\"]] = \"Neural\", 2\n",
    "\n",
    "results[\"dataset\"] = results[\"dataset_name\"].map({\n",
    "    \"airfoil_log\": \"Airfoil (R.)\",\n",
    "    \"flchain_1000\": \"flchain (R.)\",\n",
    "    \"stress-strain-lot-max-0.2\": \"Stress-Strain (R.)\",\n",
    "    \"synthetic_tumor_wilkerson_1\": \"Tumer (S.)\",\n",
    "    \"sine_trans_200_20\": \"Sine (S.)\",\n",
    "    \"beta_900_20\": \"Beta (S.)\",\n",
    "})\n",
    "\n",
    "results[\"ord_dataset\"] = results[\"dataset_name\"].map({\n",
    "    \"airfoil_log\": 0,\n",
    "    \"flchain_1000\": 1,\n",
    "    \"stress-strain-lot-max-0.2\": 2,\n",
    "    \"synthetic_tumor_wilkerson_1\": 3,\n",
    "    \"sine_trans_200_20\": 4,\n",
    "    \"beta_900_20\": 5,\n",
    "})\n",
    "results = results.sort_values([\"ord_dataset\", \"ord_method\"])\n",
    "results = results[[\"method\", \"rmse\", \"rmse_std\", \"mse\", \"mse_std\"]]\n",
    "results[[\"rmse\", \"rmse_std\", \"mse\", \"mse_std\"]] = results[[\"rmse\", \"rmse_std\", \"mse\", \"mse_std\"]].round(3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35116cc3-f241-490a-b29b-221b0141adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latex_table(df):\n",
    "    df = df.values\n",
    "    out = \"\"\n",
    "    for row in df:\n",
    "        for col in row:\n",
    "            out += \"& \" + str(col) + \" \"\n",
    "        out += \"\\\\\\\\ \\n\"\n",
    "    return out\n",
    "\n",
    "print(create_latex_table(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eaf2a5-a540-49d3-b4f0-3231cb312add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_array(ys: list):\n",
    "    max_n = max(len(y) for y in ys)\n",
    "\n",
    "    out = np.full((len(ys), max_n), np.nan)\n",
    "    for i, y in enumerate(ys):\n",
    "        out[i, :len(y)] = y\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a761a43-59dd-4ab0-a30c-290c8e50ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(dataset):\n",
    "    t, y = (\n",
    "        pd.DataFrame(\n",
    "            pad_to_array(dataset.get_X_ts_ys()[idx])\n",
    "        ).reset_index(names=\"id\")\n",
    "        for idx in [1, 2]\n",
    "    )\n",
    "    t = pd.melt(t, \"id\", value_name=\"t\")\n",
    "    y = pd.melt(y, \"id\", value_name=\"y\")\n",
    "    toplot = pd.merge(t, y)\n",
    "    return toplot, so.Plot(\n",
    "        toplot,\n",
    "        x=\"t\",\n",
    "        y=\"y\",\n",
    "        color=\"id\"\n",
    "    ).add(\n",
    "        so.Lines(alpha=0.3),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f59e3a-ff2b-49d9-ab98-ec70778db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf_hist(dataset):\n",
    "    values = np.array([\n",
    "        [acf(y, nlags=1)[1] for y in dataset.get_X_ts_ys()[-1]],\n",
    "        [pacf(y, nlags=1)[1] for y in dataset.get_X_ts_ys()[-1]],\n",
    "    ]).T\n",
    "    values = pd.DataFrame(values, columns=[\"acf\", \"pacf\"]).reset_index(names=\"id\")\n",
    "    toplot = pd.melt(values, \"id\")\n",
    "    print(values.mean(0))\n",
    "    return toplot, so.Plot(\n",
    "        toplot,\n",
    "        x=\"value\",\n",
    "    ).add(\n",
    "        so.Bars(), so.Hist(),\n",
    "    ).facet(col=\"variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63767dd-9508-4b21-8dc2-e9dc4c90774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toplot = []\n",
    "\n",
    "for dataset_name in (\n",
    "    \"airfoil_log\",\n",
    "    \"flchain_1000\",\n",
    "    \"stress-strain-lot-max-0.2\",\n",
    "    \"synthetic_tumor_wilkerson_1\",\n",
    "    \"sine_trans_200_20\",\n",
    "    \"beta_900_20\",\n",
    "):\n",
    "    current = load_dataset(dataset_name, dataset_description_path=\"dataset_descriptions\")\n",
    "    all_toplot.append(\n",
    "        plot_time_series(current)[0].assign(dataset=dataset_name)\n",
    "    )\n",
    "\n",
    "\n",
    "all_toplot = pd.concat(all_toplot, ignore_index=True)\n",
    "all_toplot[\"dataset\"] = all_toplot[\"dataset\"].map({\n",
    "    \"airfoil_log\": \"Airfoil (Real)\",\n",
    "    \"flchain_1000\": \"flchain (Real)\",\n",
    "    \"stress-strain-lot-max-0.2\": \"Stress-Strain (Real)\",\n",
    "    \"synthetic_tumor_wilkerson_1\": \"Tumer (Synthetic)\",\n",
    "    \"sine_trans_200_20\": \"Sine (Synthetic)\",\n",
    "    \"beta_900_20\": \"Beta (Synthetic)\",\n",
    "})\n",
    "# all_toplot[\"id\"] /= all_toplot.groupby(\"dataset\")[\"id\"].transform(\"max\")\n",
    "# so.Plot(\n",
    "#     all_toplot,\n",
    "#     x=\"t\",\n",
    "#     y=\"y\",\n",
    "#     color=\"id\"\n",
    "# ).add(\n",
    "#     so.Lines(alpha=0.3),\n",
    "# ).facet(wrap=2)\n",
    "# # all_toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee889d-8a1d-4e75-9d70-73ce83d725fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pltt = so.Plot(\n",
    "    all_toplot.assign(\n",
    "        id=all_toplot[\"id\"] / all_toplot.groupby(\"dataset\")[\"id\"].transform(\"max\"),\n",
    "    ),\n",
    "    x=\"t\",\n",
    "    y=\"y\",\n",
    "    color=\"id\",\n",
    ").add(\n",
    "    so.Lines(alpha=0.3),\n",
    "    legend=False,\n",
    ").facet(\n",
    "    col=\"dataset\", wrap=3,\n",
    ").share(\n",
    "    x=False, y=False, color=False,\n",
    ").layout(\n",
    "    size=(10, 5),\n",
    ").label(x=\"\", y=\"\")\n",
    "pltt.show()\n",
    "pltt.save(f\"{SAVE_DIR}/timeseries.png\")\n",
    "# all_toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a5a5d-0ad9-4f6c-8933-ef0d04aaa628",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_summary = (\n",
    "    all_toplot\n",
    "    .dropna()\n",
    "    .groupby([\"dataset\", \"id\"])\n",
    "    .agg({\"variable\": \"nunique\"})\n",
    "    .assign(n=1)\n",
    "    .groupby([\"dataset\"])\n",
    "    .agg({\"n\": \"sum\", \"variable\": [\"mean\", \"std\", \"max\"]})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "dataset_summary.columns = [f\"{a}_{b}\" if b else a for a, b in dataset_summary.columns]\n",
    "dataset_summary[\"dataset\"] = dataset_summary[\"dataset\"].map({\n",
    "    \"Airfoil (Real)\": \"Airfoil (R.)\",\n",
    "    \"flchain (Real)\": \"flchain (R.)\",\n",
    "    \"Stress-Strain (Real)\": \"Stress-Strain (R.)\",\n",
    "    \"Tumer (Synthetic)\": \"Tumer (S.)\",\n",
    "    \"Sine (Synthetic)\": \"Sine (S.)\",\n",
    "    \"Beta (Synthetic)\": \"Beta (S.)\",\n",
    "})\n",
    "dataset_summary = dataset_summary.round(1)\n",
    "dataset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27048c2-a27a-4d3b-bcc7-67307a4e2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrs = []\n",
    "all_toplot_2 = all_toplot.copy()\n",
    "\n",
    "for cor_type, cor_func in (\n",
    "    (\"ACF\", acf),\n",
    "    (\"PACF\", pacf),\n",
    "):\n",
    "    for diff in (0, 1):\n",
    "        if diff:\n",
    "            all_toplot_2[\"y\"] = (\n",
    "                all_toplot_2\n",
    "                .sort_values([\"dataset\", \"id\", \"variable\"])\n",
    "                .groupby([\"dataset\", \"id\"])[\"y\"]\n",
    "                .diff(diff)\n",
    "            )\n",
    "        \n",
    "        all_corrs.append(\n",
    "            all_toplot_2\n",
    "            .dropna(subset=\"y\")\n",
    "            .groupby([\"dataset\", \"id\"])[\"y\"]\n",
    "            .apply(lambda y: cor_func(y, nlags=1)[1])\n",
    "            .reset_index()\n",
    "            .groupby(\"dataset\")\n",
    "            .agg({\"y\": \"mean\"})\n",
    "            .rename(columns={\"y\": f\"{cor_type}, d={diff}\"})\n",
    "        )\n",
    "all_corrs = pd.concat(all_corrs, axis=1).round(2)\n",
    "all_corrs\n",
    "\n",
    "all_corrs = pd.concat((\n",
    "    all_corrs[[\"ACF, d=0\", \"ACF, d=1\"]].rename(columns=lambda s: s.replace(\"ACF, \", \"\")).assign(corr=\"ACF\"),\n",
    "    all_corrs[[\"PACF, d=0\", \"PACF, d=1\"]].rename(columns=lambda s: s.replace(\"PACF, \", \"\")).assign(corr=\"PACF\"),\n",
    ")).reset_index()[[\"dataset\", \"corr\", \"d=0\", \"d=1\"]]\n",
    "\n",
    "all_corrs[\"ord_dataset\"] = all_corrs[\"dataset\"].map({\n",
    "    \"Airfoil (Real)\": 0,\n",
    "    \"flchain (Real)\": 1,\n",
    "    \"Stress-Strain (Real)\": 2,\n",
    "    \"Tumer (Synthetic)\": 3,\n",
    "    \"Sine (Synthetic)\": 4,\n",
    "    \"Beta (Synthetic)\": 5,\n",
    "})\n",
    "\n",
    "all_corrs[\"dataset\"] = all_corrs[\"dataset\"].map({\n",
    "    \"Airfoil (Real)\": \"Airfoil (R.)\",\n",
    "    \"flchain (Real)\": \"flchain (R.)\",\n",
    "    \"Stress-Strain (Real)\": \"Stress-Strain (R.)\",\n",
    "    \"Tumer (Synthetic)\": \"Tumer (S.)\",\n",
    "    \"Sine (Synthetic)\": \"Sine (S.)\",\n",
    "    \"Beta (Synthetic)\": \"Beta (S.)\",\n",
    "})\n",
    "\n",
    "\n",
    "all_corrs = dataset_summary.merge(all_corrs).sort_values([\"ord_dataset\", \"corr\"])  # .drop(columns=[\"ord_dataset\", \"dataset\"])\n",
    "all_corrs = all_corrs.astype(str)\n",
    "all_corrs\n",
    "for idx, row in all_corrs.iterrows():\n",
    "    if idx % 2:\n",
    "        all_corrs.loc[idx, [\"n_sum\", \"variable_mean\", \"variable_std\", \"variable_max\"]] = \"\", \"\", \"\", \"\"\n",
    "display(all_corrs)\n",
    "all_corrs = all_corrs.drop(columns=[\"dataset\", \"ord_dataset\"])\n",
    "print(create_latex_table(all_corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afd035-2617-4c34-90bb-b80fb418f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in (\n",
    "    \"airfoil_log\",\n",
    "    \"flchain_1000\",\n",
    "    # \"stress-strain-lot-max-0.2\",\n",
    "    # \"synthetic_tumor_wilkerson_1\",\n",
    "    # \"sine_trans_200_20\",\n",
    "    # \"beta_900_20\",\n",
    "):\n",
    "    current = load_dataset(dataset_name, dataset_description_path=\"dataset_descriptions\")\n",
    "    print(f\"{'=' * 50} {dataset_name} {'=' * 50}\")\n",
    "    plot_time_series(current)[1].scale(y=\"log\").show()\n",
    "    plot_acf_pacf_hist(current)[1].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335530b3-76b7-4799-9b4f-84a79a1210f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    checkpoint = torch.load(\n",
    "        f\"{path}/lightning_logs/version_0/checkpoints/best_val.ckpt\",\n",
    "        weights_only=True,\n",
    "    )\n",
    "    state_dict = {k.replace(\"model.\", \"\"): v for k, v in checkpoint[\"state_dict\"].items()}\n",
    "    \n",
    "    with open(f\"{path}/config.pkl\", \"rb\") as f:\n",
    "        config = pickle.load(f)\n",
    "    model = TTS(config)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    transformer_loc = path[:path.find(\"TTS\")] + \"TTS\"\n",
    "    x_transformer = joblib.load(f\"{transformer_loc}/column_transformer.joblib\")\n",
    "    \n",
    "    with open(f\"{transformer_loc}/y_normalizer.json\", 'r') as f:\n",
    "        params = json.load(f)\n",
    "        y_normalizer = YNormalizer()\n",
    "        y_normalizer.set_params(params['y_mean'], params['y_std'])\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"config\": config,\n",
    "        \"x_transformer\": x_transformer,\n",
    "        \"y_normalizer\": y_normalizer,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98457e-37af-460c-bd8f-ef5d89a4fd06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from timeview.basis import BSplineBasis\n",
    "from timeview.data import _pad_to_shape\n",
    "\n",
    "\n",
    "def get_forward_params(dataset, model_dict):\n",
    "    with torch.no_grad():\n",
    "        max_n = max(len(y) for y in dataset.ys)\n",
    "        \n",
    "        bspline = BSplineBasis(\n",
    "            model_dict[\"config\"].n_basis,\n",
    "            (0, model_dict[\"config\"].T),\n",
    "            internal_knots=model_dict[\"config\"].internal_knots,\n",
    "        )\n",
    "        Phis = list(bspline.get_all_matrices(dataset.ts))\n",
    "        \n",
    "        Phis = torch.stack([\n",
    "            torch.from_numpy(_pad_to_shape( Phi, (max_n, model_dict[\"config\"].n_basis))).float()\n",
    "            for Phi in Phis\n",
    "        ], dim=0)\n",
    "        \n",
    "        \n",
    "        x = torch.from_numpy(model_dict[\"x_transformer\"].transform(dataset.X)).float()\n",
    "        ys = model_dict[\"y_normalizer\"].transform(dataset.ys)\n",
    "        ys = torch.stack([torch.from_numpy(_pad_to_shape(y, (max_n,))).float() for y in ys], dim=0)\n",
    "    \n",
    "    return x, Phis, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7c847-30a7-4c7b-8823-9b701940176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"benchmarks/summary_expanded.csv\")\n",
    "results[[\"method\", \"ord_method\"]] = \"Original\", 0\n",
    "results.loc[results[\"p\"].notna(), [\"method\", \"ord_method\"]] = \"AR(1)\", 1\n",
    "results.loc[results[\"ar_num_hidden\"].notna(), [\"method\", \"ord_method\"]] = \"Neural\", 2\n",
    "\n",
    "results[\"dataset\"] = results[\"dataset_name\"].map({\n",
    "    \"airfoil_log\": \"Airfoil (R.)\",\n",
    "    \"flchain_1000\": \"flchain (R.)\",\n",
    "    \"stress-strain-lot-max-0.2\": \"Stress-Strain (R.)\",\n",
    "    \"synthetic_tumor_wilkerson_1\": \"Tumer (S.)\",\n",
    "    \"sine_trans_200_20\": \"Sine (S.)\",\n",
    "    \"beta_900_20\": \"Beta (S.)\",\n",
    "})\n",
    "\n",
    "results[\"ord_dataset\"] = results[\"dataset_name\"].map({\n",
    "    \"airfoil_log\": 0,\n",
    "    \"flchain_1000\": 1,\n",
    "    \"stress-strain-lot-max-0.2\": 2,\n",
    "    \"synthetic_tumor_wilkerson_1\": 3,\n",
    "    \"sine_trans_200_20\": 4,\n",
    "    \"beta_900_20\": 5,\n",
    "})\n",
    "\n",
    "results = results[[\"dataset\", \"dataset_name\", \"ord_dataset\", \"method\", \"timestamp\"]]\n",
    "\n",
    "to_plot_all = []\n",
    "\n",
    "for _, row in results.iterrows():\n",
    "    run_time = row[\"timestamp\"]\n",
    "\n",
    "    path = Path(f\"benchmarks/{run_time}/TTS/final/logs/seed_35492826\")\n",
    "    benchmarks_df = pd.read_csv(\"benchmarks/summary.csv\")\n",
    "    mod = load_model(str(path))\n",
    "    \n",
    "    new = load_dataset(row[\"dataset_name\"], dataset_description_path=\"dataset_descriptions\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x, phi, y = get_forward_params(new, mod)\n",
    "        pred = mod[\"model\"](x, phi, y)\n",
    "        resid = (y - pred).numpy()\n",
    "        resid = [r[:len(y)] for r, y in zip(resid, current.ys)]\n",
    "    new.ys = resid\n",
    "    \n",
    "    to_plot_all.append(\n",
    "        plot_time_series(new)[0].assign(\n",
    "            dataset_name=row[\"dataset\"],\n",
    "            method=row[\"method\"],\n",
    "        )\n",
    "    )\n",
    "to_plot_all = pd.concat(to_plot_all, ignore_index=True)\n",
    "to_plot_all[\"method\"] = pd.Categorical(\n",
    "    to_plot_all[\"method\"],\n",
    "    [\n",
    "        \"Original\",\n",
    "        \"AR(1)\",\n",
    "        \"Neural\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "to_plot_all = to_plot_all.sort_values([\"dataset_name\", \"method\", \"id\", \"t\"])\n",
    "to_plot_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00919a33-4c9f-44e2-a062-e0d0f773d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Airfoil (R.)\",\n",
    "    \"flchain (R.)\",\n",
    "    \"Stress-Strain (R.)\",\n",
    "    \"Tumer (S.)\",\n",
    "    \"Sine (S.)\",\n",
    "    \"Beta (S.)\",\n",
    "]\n",
    "\n",
    "\n",
    "for pattern, data_type in (\n",
    "    (\"(R.)\", \"real\"), (\"(S.)\", \"synth\")\n",
    "):\n",
    "    toplot_now = to_plot_all[to_plot_all[\"dataset_name\"].str.contains(pattern)].copy()\n",
    "    toplot_now[\"id\"] /= toplot_now.groupby([\"dataset_name\", \"method\"])[\"id\"].transform(\"max\")\n",
    "    \n",
    "    toplot_now[\"dataset_name\"] = pd.Categorical(\n",
    "        toplot_now[\"dataset_name\"],\n",
    "        [cat for cat in categories if pattern in cat],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    pltt = so.Plot(\n",
    "        toplot_now,\n",
    "        x=\"t\",\n",
    "        y=\"y\",\n",
    "    ).add(\n",
    "        so.Lines(alpha=0.3),\n",
    "        color=\"id\",\n",
    "        legend=False,\n",
    "    ).facet(\n",
    "        row=\"dataset_name\", col=\"method\",\n",
    "    ).share(\n",
    "        x=False, y=True, color=False,\n",
    "    ).layout(\n",
    "        size=(10, 10),\n",
    "    ).label(x=\"\", y=\"\")\n",
    "    pltt.show()\n",
    "    pltt.save(f\"{SAVE_DIR}/residuals_{data_type}.png\")\n",
    "    # all_toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c124b2-322d-42f6-b2d0-053bb607a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Airfoil (R.)\",\n",
    "    \"flchain (R.)\",\n",
    "    \"Stress-Strain (R.)\",\n",
    "    \"Tumer (S.)\",\n",
    "    \"Sine (S.)\",\n",
    "    \"Beta (S.)\",\n",
    "]\n",
    "\n",
    "\n",
    "for cat in categories:\n",
    "    toplot_now = to_plot_all[to_plot_all[\"dataset_name\"] == cat].copy()\n",
    "    toplot_now[\"id\"] /= toplot_now.groupby([\"dataset_name\", \"method\"])[\"id\"].transform(\"max\")\n",
    "    \n",
    "    # toplot_now[\"dataset_name\"] = pd.Categorical(\n",
    "    #     toplot_now[\"dataset_name\"],\n",
    "    #     [cat for cat in categories if pattern in cat],\n",
    "    #     ordered=True,\n",
    "    # )\n",
    "\n",
    "    pltt = so.Plot(\n",
    "        toplot_now,\n",
    "        x=\"t\",\n",
    "        y=\"y\",\n",
    "    ).add(\n",
    "        so.Lines(alpha=0.3),\n",
    "        color=\"id\",\n",
    "        legend=False,\n",
    "    ).facet(\n",
    "        row=\"dataset_name\", col=\"method\",\n",
    "    ).share(\n",
    "        x=False, y=True, color=False,\n",
    "    ).layout(\n",
    "        size=(10, 3.5),\n",
    "    ).label(x=\"\", y=\"\")\n",
    "    pltt.show()\n",
    "    pltt.save(f\"{SAVE_DIR}/{cat}.png\")\n",
    "    # all_toplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e902f89-197b-4d9e-9d77-bce7d582be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_time in (\n",
    "    \"2024-10-27T05-15-31\",\n",
    "    \"2024-10-27T05-19-44\",\n",
    "    \"2024-10-27T05-34-15\",\n",
    "):\n",
    "\n",
    "    path = Path(f\"benchmarks/{run_time}/TTS/final/logs/seed_35492826\")\n",
    "    benchmarks_df = pd.read_csv(\"benchmarks/summary.csv\")\n",
    "    dataset_name = benchmarks_df.loc[benchmarks_df[\"timestamp\"] == run_time, \"dataset_name\"].values[0]\n",
    "    mod = load_model(str(path))\n",
    "    \n",
    "    new = load_dataset(dataset_name, dataset_description_path=\"dataset_descriptions\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x, phi, y = get_forward_params(new, mod)\n",
    "        pred = mod[\"model\"](x, phi, y)\n",
    "        resid = (y - pred).numpy()\n",
    "        resid = [r[:len(y)] for r, y in zip(resid, current.ys)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    new.ys = resid\n",
    "    print(dataset_name)\n",
    "    plot_time_series(new)[1].show()\n",
    "    plot_acf_pacf_hist(new)[1].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4a4b5-894a-4a36-a3fc-092b864efcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nu_n(phi, n):\n",
    "    toeplitz = np.abs(np.arange(n)[None,:] - np.arange(n)[:,None])\n",
    "    return np.power(phi, toeplitz).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1bac9-838d-45b8-adae-627aa4ba97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for phi in np.linspace(0, 1, 100):\n",
    "    for n in (20, 50, 100, 200):\n",
    "        results.append({\n",
    "            \"n\": n,\n",
    "            \"phi\": phi,\n",
    "            \"v_orig\": nu_n(phi, n) / n ** 3,\n",
    "            \"v_new_series\": nu_n(phi, n) / n ** 2 / (n + 1),\n",
    "            \"v_new_time\": nu_n(phi, n + 1) / n / (n + 1) ** 2,\n",
    "            \"ratio\": n / (n + 1) * nu_n(phi, n+1) / nu_n(phi, n)\n",
    "        })\n",
    "results = pd.DataFrame(results)\n",
    "results[\"n\"] = pd.Categorical(results[\"n\"])\n",
    "# results[[\"v_orig\", \"v_new_series\", \"v_new_time\", \"ratio\"]] = np.sqrt(results[[\"v_orig\", \"v_new_series\", \"v_new_time\", \"ratio\"]])\n",
    "results[\"ratio\"] -= 1\n",
    "\n",
    "so.Plot(\n",
    "    results,\n",
    "    x=\"phi\",\n",
    "    y=\"ratio\",\n",
    "    color=\"n\",\n",
    ").add(\n",
    "    so.Lines()\n",
    ").scale(\n",
    "    y=\"sqrt\",\n",
    ").label(\n",
    "    x=\"Auto-correlation\", y=\"Ratio\",\n",
    ").layout(\n",
    "    size=(8, 4),\n",
    ").save(f\"{SAVE_DIR}/ratio.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timeview]",
   "language": "python",
   "name": "conda-env-timeview-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
